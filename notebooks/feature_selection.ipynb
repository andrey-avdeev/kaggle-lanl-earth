{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LANL Earhquake prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.float_format = '{:,.10f}'.format\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "# Visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_BASE = '..data/processed/train/features_fast.csv'\n",
    "FEATURES_BASE_DENOISE = 'features_den_fast.csv'\n",
    "FEATURES_FOLDS_DENOISE = ''\n",
    "FEATURES_ = 'features_slow.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f = pd.read_csv(CACHE_DIR+FEATURES_F,index_col='id')\n",
    "data_d_f = pd.read_csv(CACHE_DIR+FEATURES_D_F,index_col='id')\n",
    "data_s = pd.read_csv(CACHE_DIR+FEATURES_S,index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x__abs_energy</th>\n",
       "      <th>x__absolute_sum_of_changes</th>\n",
       "      <th>x__agg_autocorrelation__f_agg_\"mean\"__maxlag_40</th>\n",
       "      <th>x__agg_autocorrelation__f_agg_\"median\"__maxlag_40</th>\n",
       "      <th>x__agg_autocorrelation__f_agg_\"var\"__maxlag_40</th>\n",
       "      <th>x__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"intercept\"</th>\n",
       "      <th>x__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"rvalue\"</th>\n",
       "      <th>x__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"slope\"</th>\n",
       "      <th>x__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"stderr\"</th>\n",
       "      <th>x__agg_linear_trend__f_agg_\"max\"__chunk_len_50__attr_\"intercept\"</th>\n",
       "      <th>...</th>\n",
       "      <th>x__symmetry_looking__r_0.9500000000000001</th>\n",
       "      <th>x__time_reversal_asymmetry_statistic__lag_1</th>\n",
       "      <th>x__time_reversal_asymmetry_statistic__lag_2</th>\n",
       "      <th>x__time_reversal_asymmetry_statistic__lag_3</th>\n",
       "      <th>x__value_count__value_-1</th>\n",
       "      <th>x__value_count__value_0</th>\n",
       "      <th>x__value_count__value_1</th>\n",
       "      <th>x__variance</th>\n",
       "      <th>x__variance_larger_than_standard_deviation</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10,247.0000000000</td>\n",
       "      <td>391,980.0000000000</td>\n",
       "      <td>-0.0196169172</td>\n",
       "      <td>-0.0292105689</td>\n",
       "      <td>0.0771727933</td>\n",
       "      <td>11.4728051641</td>\n",
       "      <td>-0.1604799308</td>\n",
       "      <td>-0.0001705898</td>\n",
       "      <td>0.0000085674</td>\n",
       "      <td>15.5494230812</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>0.2592567901</td>\n",
       "      <td>3.8303954772</td>\n",
       "      <td>-4.1183647346</td>\n",
       "      <td>3,622.0000000000</td>\n",
       "      <td>5,741.0000000000</td>\n",
       "      <td>8,406.0000000000</td>\n",
       "      <td>26.0211102805</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>1.4307971859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31,377.0000000000</td>\n",
       "      <td>405,226.0000000000</td>\n",
       "      <td>-0.0296423639</td>\n",
       "      <td>-0.0473553483</td>\n",
       "      <td>0.0950035692</td>\n",
       "      <td>10.8740597116</td>\n",
       "      <td>-0.0420251683</td>\n",
       "      <td>-0.0000653812</td>\n",
       "      <td>0.0000126924</td>\n",
       "      <td>14.9988208375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>-6.4017320231</td>\n",
       "      <td>-0.2259793594</td>\n",
       "      <td>2.8093990426</td>\n",
       "      <td>3,888.0000000000</td>\n",
       "      <td>5,853.0000000000</td>\n",
       "      <td>8,557.0000000000</td>\n",
       "      <td>43.4123094122</td>\n",
       "      <td>1.0000000000</td>\n",
       "      <td>1.3914988931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 789 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x__abs_energy  x__absolute_sum_of_changes  \\\n",
       "id                                                 \n",
       "0  10,247.0000000000          391,980.0000000000   \n",
       "1  31,377.0000000000          405,226.0000000000   \n",
       "\n",
       "    x__agg_autocorrelation__f_agg_\"mean\"__maxlag_40  \\\n",
       "id                                                    \n",
       "0                                     -0.0196169172   \n",
       "1                                     -0.0296423639   \n",
       "\n",
       "    x__agg_autocorrelation__f_agg_\"median\"__maxlag_40  \\\n",
       "id                                                      \n",
       "0                                       -0.0292105689   \n",
       "1                                       -0.0473553483   \n",
       "\n",
       "    x__agg_autocorrelation__f_agg_\"var\"__maxlag_40  \\\n",
       "id                                                   \n",
       "0                                     0.0771727933   \n",
       "1                                     0.0950035692   \n",
       "\n",
       "    x__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"intercept\"  \\\n",
       "id                                                                     \n",
       "0                                       11.4728051641                  \n",
       "1                                       10.8740597116                  \n",
       "\n",
       "    x__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"rvalue\"  \\\n",
       "id                                                                  \n",
       "0                                       -0.1604799308               \n",
       "1                                       -0.0420251683               \n",
       "\n",
       "    x__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"slope\"  \\\n",
       "id                                                                 \n",
       "0                                       -0.0001705898              \n",
       "1                                       -0.0000653812              \n",
       "\n",
       "    x__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"stderr\"  \\\n",
       "id                                                                  \n",
       "0                                        0.0000085674               \n",
       "1                                        0.0000126924               \n",
       "\n",
       "    x__agg_linear_trend__f_agg_\"max\"__chunk_len_50__attr_\"intercept\"  \\\n",
       "id                                                                     \n",
       "0                                       15.5494230812                  \n",
       "1                                       14.9988208375                  \n",
       "\n",
       "       ...       x__symmetry_looking__r_0.9500000000000001  \\\n",
       "id     ...                                                   \n",
       "0      ...                                    1.0000000000   \n",
       "1      ...                                    1.0000000000   \n",
       "\n",
       "    x__time_reversal_asymmetry_statistic__lag_1  \\\n",
       "id                                                \n",
       "0                                  0.2592567901   \n",
       "1                                 -6.4017320231   \n",
       "\n",
       "    x__time_reversal_asymmetry_statistic__lag_2  \\\n",
       "id                                                \n",
       "0                                  3.8303954772   \n",
       "1                                 -0.2259793594   \n",
       "\n",
       "    x__time_reversal_asymmetry_statistic__lag_3  x__value_count__value_-1  \\\n",
       "id                                                                          \n",
       "0                                 -4.1183647346          3,622.0000000000   \n",
       "1                                  2.8093990426          3,888.0000000000   \n",
       "\n",
       "    x__value_count__value_0  x__value_count__value_1   x__variance  \\\n",
       "id                                                                   \n",
       "0          5,741.0000000000         8,406.0000000000 26.0211102805   \n",
       "1          5,853.0000000000         8,557.0000000000 43.4123094122   \n",
       "\n",
       "    x__variance_larger_than_standard_deviation            y  \n",
       "id                                                           \n",
       "0                                 1.0000000000 1.4307971859  \n",
       "1                                 1.0000000000 1.3914988931  \n",
       "\n",
       "[2 rows x 789 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_s.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = data_d_f['y']\n",
    "X_all = data_d_f.drop('y',axis=1).join(data_s.drop('y',axis=1))\n",
    "# X_all = data_s.drop('y',axis=1)\n",
    "# X_all = data_d_f.drop('y',axis=1).join(data_s.drop('y',axis=1),rsuffix='s_').join(data_f.drop('y',axis=1),rsuffix='f_')\n",
    "# X_all = data_f.drop('y',axis=1).join(data_s.drop('y',axis=1),rsuffix='s_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_f.shape: (4194, 116)\n",
      "data_s.shape: (4194, 789)\n",
      "X.shape: (4194, 903)\n"
     ]
    }
   ],
   "source": [
    "print('data_f.shape:',data_f.shape)\n",
    "print('data_s.shape:',data_s.shape)\n",
    "print('X.shape:',X_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning from NaN,infinity or too large values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.any(np.isnan(X_all)):\n",
    "    X_all.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outer Cross-Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from src.settings import RANDOM_STATE\n",
    "X, X_cross, y, y_cross = train_test_split(X_all, y_all, test_size=0.15, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.grid_search import GridSearch as gs\n",
    "from src.grid import ARD_REGRESSION,BAYESIAN_RIDGE,ELASTIC_NET,ELASTIC_NET_CV,\\\n",
    "HUBER_REGRESSOR,KERNEL_RIDGE,LARS,LARS_CV,LASSO,LASSO_CV,LASSO_LARS,LASSO_LARS_CV,\\\n",
    "LASSO_LARS_IC,LINEAR_REGRESSION,MULTITASK_ELASTIC_NET,MULTITASK_ELASTIC_NET_CV,\\\n",
    "MULTITASK_LASSO,MULTITASK_LASSO_CV,ORTOGONAL_MATCHING_PURSUIT,ORTOGONAL_MATCHING_PURSUIT_CV,\\\n",
    "PASSIVE_AGGRESSIVE_REGRESSOR,RANSAC_REGRESSOR,RIDGE,RIDGE_CV,SGD_REGRESSOR,THEIL_SEN_REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ARDRegression,BayesianRidge,ElasticNet,ElasticNetCV\n",
    "from sklearn.linear_model import HuberRegressor, Lars,LarsCV,Lasso,LassoCV,LassoLars,LassoLarsCV\n",
    "from sklearn.linear_model import LassoLarsIC,LinearRegression,MultiTaskElasticNet,MultiTaskElasticNetCV\n",
    "from sklearn.linear_model import MultiTaskLasso, MultiTaskLassoCV, PassiveAggressiveRegressor, RANSACRegressor\n",
    "from sklearn.linear_model import Ridge, RidgeCV, SGDRegressor, TheilSenRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "{'alpha': 1.5975975975975976, 'random_state': 42} loss: 2.0603147785511005 minutes_left: 0.3073072791099548 k_features_count: 50\n",
      "50\n",
      "{'alpha': 2.195195195195195, 'random_state': 42} loss: 2.087616549962874 minutes_left: 0.29331560532251993 k_features_count: 50\n",
      "50\n",
      "{'alpha': 10.362362362362363, 'random_state': 42} loss: 2.0872795436437803 minutes_left: 0.2965218226114909 k_features_count: 50\n",
      "100\n",
      "{'alpha': 15.342342342342343, 'random_state': 42} loss: 2.077441934417125 minutes_left: 0.4628608028093974 k_features_count: 100\n",
      "100\n",
      "{'alpha': 3.9879879879879883, 'random_state': 42} loss: 2.088354734451947 minutes_left: 0.46168492635091146 k_features_count: 100\n",
      "100\n",
      "{'alpha': 8.76876876876877, 'random_state': 42} loss: 2.087580281780778 minutes_left: 0.4685291330019633 k_features_count: 100\n",
      "200\n",
      "{'alpha': 59.36536536536537, 'random_state': 42} loss: 2.088282129101417 minutes_left: 1.2155125578244528 k_features_count: 200\n",
      "200\n",
      "{'alpha': 41.83583583583584, 'random_state': 42} loss: 2.1065007576427 minutes_left: 1.26584050655365 k_features_count: 200\n",
      "200\n",
      "{'alpha': 100.002002002002, 'random_state': 42} loss: 2.1048502182702364 minutes_left: 1.2807002305984496 k_features_count: 200\n",
      "CPU times: user 24min 26s, sys: 23min 16s, total: 47min 42s\n",
      "Wall time: 6min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "i=0\n",
    "k_features = [50,100,200]\n",
    "scalers = []\n",
    "\n",
    "cv_dict['ridge'] = {}\n",
    "for k_feature in k_features:\n",
    "    cv_dict['ridge'][k_feature] = {\n",
    "        'best_params':[],\n",
    "        'best_score':[],\n",
    "        'time_left':[],\n",
    "        'mae':[]\n",
    "    }\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(k_feature)\n",
    "        i+=1\n",
    "    #     print('kfold.iteration=',i)\n",
    "        X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    #     print('VarianceThreshold')\n",
    "        var_selector = VarianceThreshold().fit(X_train)\n",
    "\n",
    "    #     print('before.X.shape:',X_train.shape)\n",
    "        X_train = X_train[X_train.columns[var_selector.get_support(indices=True)]]\n",
    "    #     print('after.X.shape:',X_train.shape)\n",
    "\n",
    "    #     print('SelectKBest')\n",
    "#         pca = PCA(n_components=k_feature)\n",
    "#         pca = pca.fit(X_train)\n",
    "        \n",
    "#         X_train = pd.DataFrame(data=pca.transform(X_train))\n",
    "        \n",
    "        \n",
    "        kbest_selector = SelectKBest(f_regression, k=k_feature)\n",
    "        kbest_selector = kbest_selector.fit(X_train, y_train)\n",
    "        X_train = X_train[X_train.columns[kbest_selector.get_support(indices=True)]]\n",
    "\n",
    "    #     print('Scaler')\n",
    "#         scaler = StandardScaler()\n",
    "        scaler = RobustScaler()\n",
    "        scaler = scaler.fit(X_train)\n",
    "\n",
    "        X_train_scale = scaler.transform(X_train)\n",
    "\n",
    "        best_params, best_score, time_left = gs.best_parameters(Ridge(),RIDGE,X_train_scale,y_train)\n",
    "        print(best_params,'loss:',best_score,'minutes_left:',time_left,'k_features_count:',k_feature)\n",
    "\n",
    "    #     test dataset\n",
    "        \n",
    "        X_test = X_test[X_test.columns[var_selector.get_support(indices=True)]]\n",
    "#         X_test = pca.transform(X_test)\n",
    "        X_test = X_test[X_test.columns[kbest_selector.get_support(indices=True)]]\n",
    "        X_test_scale = scaler.transform(X_test)\n",
    "\n",
    "        model = Ridge(**best_params)\n",
    "        model.fit(X_train_scale,y_train)\n",
    "        prediction = model.predict(X_test_scale)\n",
    "\n",
    "        cv_dict['ridge'][k_feature]['best_params'].append(best_params)\n",
    "        cv_dict['ridge'][k_feature]['best_score'].append(best_score)\n",
    "        cv_dict['ridge'][k_feature]['time_left'].append(time_left)\n",
    "        cv_dict['ridge'][k_feature]['mae'].append(mean_absolute_error(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cv(cv_dict):\n",
    "    for model_name,cv in cv_dict.items():\n",
    "        for key,val in cv.items():\n",
    "            print(model_name,key,np.mean(val['mae']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge 50 2.0737284539247804\n",
      "ridge 100 2.0795526133288846\n",
      "ridge 200 2.1005824361360768\n"
     ]
    }
   ],
   "source": [
    "print_cv(cv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge 50 2.0737284539247804\n",
      "ridge 100 2.0795526133288846\n",
      "ridge 200 2.1005824361360768\n"
     ]
    }
   ],
   "source": [
    "print_cv(cv_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "\n",
    "def make_predictions(estimator, features, target, test=None, plot=True, lgb=False):\n",
    "    \"\"\"Train the estimator and make predictions for oof and test data.\"\"\"\n",
    "    folds = KFold(num_folds, shuffle=True, random_state=2019)\n",
    "    oof_predictions = np.zeros(features.shape[0])\n",
    "    if test is not None:\n",
    "        sub_predictions = np.zeros(test.shape[0])\n",
    "    for (train_index, valid_index) in folds.split(features, target):\n",
    "        \n",
    "        if lgb:\n",
    "            estimator.fit(features[train_index], target[train_index],\n",
    "                          early_stopping_rounds=100, verbose=False,\n",
    "                          eval_set=[(features[train_index], target[train_index]),\n",
    "                                    (features[valid_index], target[valid_index])])\n",
    "        else:\n",
    "            estimator.fit(features[train_index], target[train_index])\n",
    "        oof_predictions[valid_index] = estimator.predict(features[valid_index]).flatten()\n",
    "        if test is not None:\n",
    "            sub_predictions += estimator.predict(test).flatten() / num_folds\n",
    "    \n",
    "    # Plot out-of-fold predictions vs actual values\n",
    "    if plot:\n",
    "        fig, axis = plt.subplots(1, 2, figsize=(12,5))\n",
    "        ax1, ax2 = axis\n",
    "        ax1.set_xlabel('actual')\n",
    "        ax1.set_ylabel('predicted')\n",
    "        ax2.set_xlabel('train index')\n",
    "        ax2.set_ylabel('time to failure')\n",
    "        ax1.scatter(target, oof_predictions, color='brown')\n",
    "        ax1.plot([(0, 0), (20, 20)], [(0, 0), (20, 20)], color='blue')\n",
    "        ax2.plot(target, color='blue', label='y_train')\n",
    "        ax2.plot(oof_predictions, color='orange')\n",
    "    if test is not None:\n",
    "        return oof_predictions, sub_predictions\n",
    "    else:\n",
    "        return oof_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_params = {\n",
    "    'objective': 'regression_l1',\n",
    "    'boosting': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'random_seed': 19,\n",
    "    'n_estimators': 20000,\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.05, 0.01, 0.005],\n",
    "    'num_leaves': list(range(8, 92, 4)),\n",
    "    'max_depth': [3, 4, 5, 6, 8, 12, 16, -1],\n",
    "    'feature_fraction': [0.8, 0.85, 0.9, 0.95, 1],\n",
    "    'subsample': [0.8, 0.85, 0.9, 0.95, 1],\n",
    "    'lambda_l1': [0, 0.1, 0.2, 0.4, 0.6, 0.9],\n",
    "    'lambda_l2': [0, 0.1, 0.2, 0.4, 0.6, 0.9],\n",
    "    'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'min_gain_to_split': [0, 0.001, 0.01, 0.1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_selector = VarianceThreshold().fit(X)\n",
    "\n",
    "#     print('before.X.shape:',X_train.shape)\n",
    "X_train = X_train[X_train.columns[var_selector.get_support(indices=True)]]\n",
    "#     print('after.X.shape:',X_train.shape)\n",
    "\n",
    "#     print('SelectKBest')\n",
    "#         pca = PCA(n_components=k_feature)\n",
    "#         pca = pca.fit(X_train)\n",
    "\n",
    "#         X_train = pd.DataFrame(data=pca.transform(X_train))\n",
    "\n",
    "\n",
    "kbest_selector = SelectKBest(f_regression, k=k_feature)\n",
    "kbest_selector = kbest_selector.fit(X_train, y_train)\n",
    "X_train = X_train[X_train.columns[kbest_selector.get_support(indices=True)]]\n",
    "\n",
    "#     print('Scaler')\n",
    "#         scaler = StandardScaler()\n",
    "scaler = RobustScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scale = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.0586316906118114 1339\n",
      "1 2.0559471740797006 53\n",
      "2 2.0559471740797006 53\n",
      "3 2.0559471740797006 53\n",
      "4 2.0539913052066865 675\n",
      "5 2.0539913052066865 675\n",
      "6 2.0539913052066865 675\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-9872ab82dd29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     result = lgb.cv(params, dataset, nfold=5, early_stopping_rounds=100,\n\u001b[0;32m---> 13\u001b[0;31m                     stratified=False)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l1-mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks)\u001b[0m\n\u001b[1;32m    449\u001b[0m                                     \u001b[0mend_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agg_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mhandlerFunction\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboosters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandlerFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1526\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1527\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1529\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import lightgbm as lgb\n",
    "dataset = lgb.Dataset(X, label=y)  # no need to scale features\n",
    "\n",
    "best_score = 999\n",
    "best_params= None\n",
    "best_nrounds = None\n",
    "\n",
    "for i in range(500):\n",
    "    params = {k: random.choice(v) for k, v in param_grid.items()}\n",
    "    params.update(fixed_params)\n",
    "    result = lgb.cv(params, dataset, nfold=5, early_stopping_rounds=100,\n",
    "                    stratified=False)\n",
    "    \n",
    "    if result['l1-mean'][-1] < best_score:\n",
    "        best_score = result['l1-mean'][-1]\n",
    "        best_params = params\n",
    "        best_nrounds = len(result['l1-mean'])\n",
    "        \n",
    "    print(i,best_score,best_nrounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best mean score: {:.4f}, num rounds: {}\".format(best_score, best_nrounds))\n",
    "print(best_params)\n",
    "gb_oof = make_predictions(lgb.LGBMRegressor(**best_params), X.values, y, lgb=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
